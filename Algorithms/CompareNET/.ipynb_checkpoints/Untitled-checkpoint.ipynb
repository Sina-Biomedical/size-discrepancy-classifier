{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import h5py\n",
    "import imageio\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageEnhance\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_directory = '../../../Data/Frames/'\n",
    "destination_directory = '../../../Data/CompareNET/Raw/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contours(image):\n",
    "    _, binarized_image = cv2.threshold(image, 80, 255, 0)\n",
    "    contours, _ = cv2.findContours(binarized_image, 1, 2)\n",
    "    contours = [contour for contour in contours if valid_contour(contour)]\n",
    "    return contours\n",
    "\n",
    "def valid_contour(contour):\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    if w < 50 or h < 50: return False\n",
    "    area = cv2.contourArea(contour)\n",
    "    return area > 200\n",
    "\n",
    "def find_boundaries(img, contours):\n",
    "    y_1, x_1 = img.shape[:2]\n",
    "    x_2 = 0\n",
    "    y_2 = 0\n",
    "\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if x < x_1: x_1 = x\n",
    "        if y < y_1: y_1 = y\n",
    "        if x + w > x_2: x_2 = x + w\n",
    "        if y + h > y_2: y_2 = y + h\n",
    "\n",
    "    return (x_1, y_1, x_2, y_2)\n",
    "\n",
    "def crop_image(image, boundaries):\n",
    "    x_1, y_1, x_2, y_2 = boundaries\n",
    "    return y_1, y_2, x_1, x_2\n",
    "\n",
    "def parse_frame(frame):\n",
    "    contours = get_contours(frame)\n",
    "    bounds = find_boundaries(frame, contours)\n",
    "    return crop(img, bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lesions = []\n",
    "root_directory = '../../../Data/AVI/'\n",
    "\n",
    "for path, subdirs, files in os.walk(root_directory):\n",
    "    for file_name in files:\n",
    "        if len(file_name) == 12:\n",
    "            file_path = os.path.join(path, file_name)\n",
    "            print(file_path)\n",
    "            avi_sequence = cv2.VideoCapture(file_path)\n",
    "            success, frame = avi_sequence.read()\n",
    "\n",
    "            count = 0\n",
    "            y1 = y2 = x1 = x2 = 0\n",
    "            image_size = 264\n",
    "\n",
    "            while success:\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                if cv2.countNonZero(frame) > 150000 and count > 4:\n",
    "\n",
    "                    if count == 5:\n",
    "                        image_size = 264 if len(frame) == 600 else 308\n",
    "\n",
    "                    if len(frame) == 600:\n",
    "                        strain = frame[100:600, 70:70+image_size]\n",
    "                        bmode = frame[100:600, 390:390+image_size]\n",
    "                    else:\n",
    "                        strain = frame[100:600, 160:160+image_size]\n",
    "                        bmode = frame[100:600, 480:480+image_size]\n",
    "\n",
    "                    if count == 5:\n",
    "                        y1, y2, x1, x2 = parse_frame(strain)\n",
    "\n",
    "                    strain_cropped = cv2.resize(strain[y1:y1 + image_size, :], dsize=(264, 264))\n",
    "                    bmode_cropped = cv2.resize(bmode[y1:y1 + image_size, :], dsize=(264, 264))\n",
    "\n",
    "                    lesion = {}\n",
    "                    lesion['strain_image'] = strain_cropped\n",
    "                    lesion['bmode_image'] = bmode_cropped\n",
    "                    lesion['classification'] = 1 if file_path[18] == 'M' else 0\n",
    "                    lesions.append(lesion)\n",
    "\n",
    "                success, frame = avi_sequence.read()\n",
    "                count += 1\n",
    "\n",
    "# TRANSFORM IMAGES\n",
    "for lesion in tqdm(lesions):\n",
    "\n",
    "    transformed_lesion_1 = {\n",
    "        'strain_image': np.fliplr(lesion['strain_image']),\n",
    "        'bmode_image': np.fliplr(lesion['bmode_image']),\n",
    "        'classification': lesion['classification']\n",
    "    }\n",
    "\n",
    "    transformed_lesion_2 = {\n",
    "        'strain_image': np.flipud(lesion['strain_image']),\n",
    "        'bmode_image': np.flipud(lesion['bmode_image']),\n",
    "        'classification': lesion['classification']\n",
    "    }\n",
    "\n",
    "    transformed_lesion_3 = {\n",
    "        'strain_image': cv2.rotate(lesion['strain_image'], cv2.ROTATE_90_CLOCKWISE),\n",
    "        'bmode_image': cv2.rotate(lesion['bmode_image'], cv2.ROTATE_90_CLOCKWISE),\n",
    "        'classification': lesion['classification']\n",
    "    }\n",
    "\n",
    "    transformed_lesion_4 = {\n",
    "        'strain_image': cv2.rotate(lesion['strain_image'], cv2.ROTATE_90_COUNTERCLOCKWISE),\n",
    "        'bmode_image': cv2.rotate(lesion['bmode_image'], cv2.ROTATE_90_COUNTERCLOCKWISE),\n",
    "        'classification': lesion['classification']\n",
    "    }\n",
    "\n",
    "    transformed_lesion_5 = {\n",
    "        'strain_image': cv2.rotate(lesion['strain_image'], cv2.ROTATE_180),\n",
    "        'bmode_image': cv2.rotate(lesion['bmode_image'], cv2.ROTATE_180),\n",
    "        'classification': lesion['classification']\n",
    "    }\n",
    "\n",
    "    lesions.append(transformed_lesion_1)\n",
    "    lesions.append(transformed_lesion_2)\n",
    "    lesions.append(transformed_lesion_3)\n",
    "    lesions.append(transformed_lesion_4)\n",
    "    lesions.append(transformed_lesion_5)\n",
    "\n",
    "training_set_size = int(0.95 * len(lesions))\n",
    "test_set_size = len(lesions) - training_set_size\n",
    "\n",
    "print(\"Dataset Size: \" + str(len(lesions)))\n",
    "print(\"Training Set Size: \" + str(training_set_size))\n",
    "print(\"Test Set Size: \" + str(test_set_size))\n",
    "\n",
    "training_images = numpy.zeros((training_set_size, 264, 264, 2))\n",
    "training_labels = numpy.zeros((training_set_size, 1))\n",
    "test_images     = numpy.zeros((training_set_size, 264, 264, 2))\n",
    "test_labels     = numpy.zeros((training_set_size, 1))\n",
    "\n",
    "for i, lesion in enumerate(tqdm(lesions)):\n",
    "    if i <= training_set_size:\n",
    "        training_images[i, [lesion['strain_image'], lesion['bmode_image']]]\n",
    "        training_labels[i, lesion['classification']]\n",
    "    else:\n",
    "        test_images[i, [lesion['strain_image'], lesion['bmode_image']]]\n",
    "        test_labels[i, lesion['classification']]\n",
    "\n",
    "training_data = h5py.File(os.path.join(destination_directory, 'training_data.h5'), 'w')\n",
    "test_data     = h5py.File(os.path.join(destination_directory, 'test_data.h5'), 'w')\n",
    "\n",
    "training_data.create_dataset('training_images', data=training_images)\n",
    "training_data.create_dataset('training_labels', data=training_labels)\n",
    "training_data.close()\n",
    "\n",
    "test_data.create_dataset('test_images', data=test_images)\n",
    "test_data.create_dataset('test_labels', data=test_labels)\n",
    "test_data.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
